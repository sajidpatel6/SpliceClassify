{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries required for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'minepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-530a8976f4fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mminepy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMINE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# from mpl_toolkits.mplot3d import Axes3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# from numpy.polynomial import polynomial as npp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'minepy'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "from minepy import MINE\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from numpy.polynomial import polynomial as npp\n",
    "# from scipy import stats\n",
    "# from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import f_regression\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('VMI_Data_BP1_V02_AK6_mod02.csv')\n",
    "\n",
    "# Sampling after cleanup\n",
    "# df_sample = df.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'LFT_SPLICE_LENGTH',\n",
      "       'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', 'BP1_S8_L',\n",
      "       'BP1_S7_L', 'BP1_S6_L', 'BP1_S5_L', 'BP1_S4_L', 'BP1_S3_L', 'BP1_S2_L',\n",
      "       'BP1_S1_ML', 'BP1_S1_MR', 'BP1_S2_R', 'BP1_S3_R', 'BP1_S4_R',\n",
      "       'BP1_S5_R', 'BP1_S6_R', 'BP1_S7_R', 'BP1_S8_R', 'PART_LENGTH',\n",
      "       'LFT_SPLICE_DELTA', 'LFT_SPLICE_PREV', 'LFT_SPLICE_MA5',\n",
      "       'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50',\n",
      "       'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20',\n",
      "       'LFT_SPLICE_SLOPE50', 'MID_SPLICE_DELTA', 'MID_SPLICE_PREV',\n",
      "       'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
      "       'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10',\n",
      "       'MID_SPLICE_SLOPE20', 'MID_SPLICE_SLOPE50', 'RHT_SPLICE_DELTA',\n",
      "       'RHT_SPLICE_PREV', 'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10',\n",
      "       'RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5',\n",
      "       'RHT_SPLICE_SLOPE10', 'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50',\n",
      "       'LFT_SPLICE_GRADE', 'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE',\n",
      "       'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'BP1_S8_L', 'BP1_S7_L', 'BP1_S6_L',\n",
      "       'BP1_S5_L', 'BP1_S4_L', 'BP1_S3_L', 'BP1_S2_L', 'BP1_S1_ML',\n",
      "       'BP1_S1_MR', 'BP1_S2_R', 'BP1_S3_R', 'BP1_S4_R', 'BP1_S5_R', 'BP1_S6_R',\n",
      "       'BP1_S7_R', 'BP1_S8_R', 'PART_LENGTH', 'LFT_SPLICE_PREV',\n",
      "       'LFT_SPLICE_MA5', 'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20',\n",
      "       'LFT_SPLICE_MA50', 'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10',\n",
      "       'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50', 'MID_SPLICE_PREV',\n",
      "       'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
      "       'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10',\n",
      "       'MID_SPLICE_SLOPE20', 'MID_SPLICE_SLOPE50', 'RHT_SPLICE_PREV',\n",
      "       'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10', 'RHT_SPLICE_MA20',\n",
      "       'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
      "       'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50', 'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['LFT_SPLICE_LENGTH', 'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', 'LFT_SPLICE_GRADE', \n",
    "              'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE', 'LFT_SPLICE_DELTA', 'MID_SPLICE_DELTA', 'RHT_SPLICE_DELTA'\n",
    "#               'LFT_SPLICE_MA5', 'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50', \n",
    "#               'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50',\n",
    "#               , 'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
    "#               'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10', 'MID_SPLICE_SLOPE20',\n",
    "#               'MID_SPLICE_SLOPE50',  'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10', \n",
    "#               'RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
    "#               'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50'\n",
    "             ], axis=1)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118219, 47)\n",
      "(118219, 47)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total  Percent\n",
      "SPLICE_GRADE         0      0.0\n",
      "BP1_S2_R             0      0.0\n",
      "LFT_SPLICE_MA5       0      0.0\n",
      "LFT_SPLICE_PREV      0      0.0\n",
      "PART_LENGTH          0      0.0\n",
      "BP1_S8_R             0      0.0\n",
      "BP1_S7_R             0      0.0\n",
      "BP1_S6_R             0      0.0\n",
      "BP1_S5_R             0      0.0\n",
      "BP1_S4_R             0      0.0\n"
     ]
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.head(10))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(x):\n",
    "    if x==0: \n",
    "        return 0\n",
    "    return 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SajidPatel\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['CUT_LENGTH2'] = df['CUT_LENGTH']**2\n",
    "df['CONV_WAIT_TIME2'] = df['CONV_WAIT_TIME']**2\n",
    "df['BP1_S8_L2'] = df['BP1_S8_L']**2\n",
    "df['BP1_S7_L2'] = df['BP1_S7_L']**2\n",
    "df['BP1_S6_L2'] = df['BP1_S6_L']**2\n",
    "df['BP1_S5_L2'] = df['BP1_S5_L']**2\n",
    "df['BP1_S4_L2'] = df['BP1_S4_L']**2\n",
    "df['BP1_S3_L2'] = df['BP1_S3_L']**2\n",
    "df['BP1_S2_L2'] = df['BP1_S2_L']**2\n",
    "df['BP1_S1_ML2'] = df['BP1_S1_ML']**2\n",
    "df['BP1_S1_MR2'] = df['BP1_S1_MR']**2\n",
    "df['BP1_S2_R2'] = df['BP1_S2_R']**2\n",
    "df['BP1_S3_R2'] = df['BP1_S3_R']**2\n",
    "df['BP1_S4_R2'] = df['BP1_S4_R']**2\n",
    "df['BP1_S5_R2'] = df['BP1_S5_R']**2\n",
    "df['BP1_S6_R2'] = df['BP1_S6_R']**2\n",
    "df['BP1_S7_R2'] = df['BP1_S7_R']**2\n",
    "df['BP1_S8_R2'] = df['BP1_S8_R']**2\n",
    "df['LFT_SPLICE_PREV2'] = df['LFT_SPLICE_PREV']**2\n",
    "df['MID_SPLICE_PREV2'] = df['MID_SPLICE_PREV']**2\n",
    "df['RHT_SPLICE_PREV2'] = df['RHT_SPLICE_PREV']**2\n",
    "\n",
    "df['CUT_LENGTH3'] = df['CUT_LENGTH'].apply(inverse)\n",
    "df['CONV_WAIT_TIME3'] = df['CONV_WAIT_TIME'].apply(inverse)\n",
    "df['BP1_S8_L3'] = df['BP1_S8_L'].apply(inverse)\n",
    "df['BP1_S7_L3'] = df['BP1_S7_L'].apply(inverse)\n",
    "df['BP1_S6_L3'] = df['BP1_S6_L'].apply(inverse)\n",
    "df['BP1_S5_L3'] = df['BP1_S5_L'].apply(inverse)\n",
    "df['BP1_S4_L3'] = df['BP1_S4_L'].apply(inverse)\n",
    "df['BP1_S3_L3'] = df['BP1_S3_L'].apply(inverse)\n",
    "df['BP1_S2_L3'] = df['BP1_S2_L'].apply(inverse)\n",
    "df['BP1_S1_ML3'] = df['BP1_S1_ML'].apply(inverse)\n",
    "df['BP1_S1_MR3'] = df['BP1_S1_MR'].apply(inverse)\n",
    "df['BP1_S2_R3'] = df['BP1_S2_R'].apply(inverse)\n",
    "df['BP1_S3_R3'] = df['BP1_S3_R'].apply(inverse)\n",
    "df['BP1_S4_R3'] = df['BP1_S4_R'].apply(inverse)\n",
    "df['BP1_S5_R3'] = df['BP1_S5_R'].apply(inverse)\n",
    "df['BP1_S6_R3'] = df['BP1_S6_R'].apply(inverse)\n",
    "df['BP1_S7_R3'] = df['BP1_S7_R'].apply(inverse)\n",
    "df['BP1_S8_R3'] = df['BP1_S8_R'].apply(inverse)\n",
    "df['LFT_SPLICE_PREV3'] = df['LFT_SPLICE_PREV'].apply(inverse)\n",
    "df['MID_SPLICE_PREV3'] = df['MID_SPLICE_PREV'].apply(inverse)\n",
    "df['RHT_SPLICE_PREV3'] = df['RHT_SPLICE_PREV'].apply(inverse)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "mycols = ['CUT_LENGTH', 'CONV_WAIT_TIME', 'BP1_S8_L', 'BP1_S7_L', 'BP1_S6_L', 'BP1_S5_L', 'BP1_S4_L', 'BP1_S3_L', \n",
    "          'BP1_S2_L', 'BP1_S1_ML', 'BP1_S1_MR', 'BP1_S2_R', 'BP1_S3_R', 'BP1_S4_R', 'BP1_S5_R', 'BP1_S6_R',\n",
    "          'BP1_S7_R', 'BP1_S8_R', 'PART_LENGTH', 'LFT_SPLICE_PREV', 'MID_SPLICE_PREV', 'RHT_SPLICE_PREV', \n",
    "          'CUT_LENGTH2', 'CONV_WAIT_TIME2', 'BP1_S8_L2', 'BP1_S7_L2', 'BP1_S6_L2', 'BP1_S5_L2', \n",
    "          'BP1_S4_L2', 'BP1_S3_L2', 'BP1_S2_L2', 'BP1_S1_ML2', 'BP1_S1_MR2', 'BP1_S2_R2', 'BP1_S3_R2', 'BP1_S4_R2', \n",
    "          'BP1_S5_R2', 'BP1_S6_R2',  'BP1_S7_R2', 'BP1_S8_R2', 'LFT_SPLICE_PREV2', 'MID_SPLICE_PREV2', \n",
    "          'RHT_SPLICE_PREV2','LFT_SPLICE_MA5', 'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50',  \n",
    "          'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50', \n",
    "          'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20', 'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', \n",
    "          'MID_SPLICE_SLOPE10', 'MID_SPLICE_SLOPE20', 'MID_SPLICE_SLOPE50', 'RHT_SPLICE_MA5', \n",
    "          'RHT_SPLICE_MA10','RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
    "          'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50','CUT_LENGTH3', 'CONV_WAIT_TIME3', 'BP1_S8_L3', 'BP1_S7_L3',\n",
    "          'BP1_S6_L3', 'BP1_S5_L3', 'BP1_S4_L3', 'BP1_S3_L3', 'BP1_S2_L3', 'BP1_S1_ML3', 'BP1_S1_MR3', \n",
    "          'BP1_S2_R3', 'BP1_S3_R3', 'BP1_S4_R3', 'BP1_S5_R3', 'BP1_S6_R3', 'BP1_S7_R3', 'BP1_S8_R3', \n",
    "          'LFT_SPLICE_PREV3', 'MID_SPLICE_PREV3', 'RHT_SPLICE_PREV3']\n",
    "df[mycols] = scaler.fit_transform(df[mycols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby('SPLICE_GRADE', group_keys=False).apply(lambda x: x.sample(120))\n",
    "# df['SPLICE_GRADE'] = df.apply(numericSG, axis=1) \n",
    "\n",
    "spliceGrade = {'Bad': 0, 'OK': 1, 'Good': 1} \n",
    "# spliceGrade = {'Bad': 0, 'OK': 1, 'Good': 2} \n",
    "df.SPLICE_GRADE = [spliceGrade[item] for item in df.SPLICE_GRADE] \n",
    "\n",
    "\n",
    "# df.to_csv('temp.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SPLICE_GRADE'], axis=1)\n",
    "y = df['SPLICE_GRADE']\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SajidPatel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f909e60b5cf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RFE\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpval\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mf_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8806bab2cbc7>\u001b[0m in \u001b[0;36mrank_to_dict\u001b[1;34m(ranks, names, order)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrank_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mminmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranks\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'map'"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    " \n",
    "size = 750\n",
    "\n",
    "# names = [\"x%s\" % i for i in range(1,15)]\n",
    "names = X.columns\n",
    "\n",
    "ranks = {}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X,y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "\n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "rfe = RFE(rf, n_features_to_select=5)\n",
    "rfe.fit(X,y)\n",
    "ranks[\"RFE\"] = rank_to_dict(list(map(float, rfe.ranking_)), names, order=-1)\n",
    " \n",
    "f, pval  = f_regression(X, y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    mine.compute_score(X[:,i], y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    " \n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    " \n",
    " \n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks[\"RFE\"] = rank_to_dict(list(map(float, rfe.ranking_)), names, order=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MINE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-bd84e593be79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Corr.\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMINE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmic_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MINE' is not defined"
     ]
    }
   ],
   "source": [
    "f, pval  = f_regression(X, y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    mine.compute_score(X[:,i], y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    " \n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    " \n",
    " \n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
