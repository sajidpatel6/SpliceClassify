{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries required for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our classifiers\n",
    "ADA = AdaBoostClassifier(n_estimators=100, random_state=7)\n",
    "BNB = BernoulliNB()\n",
    "GNB = GaussianNB()\n",
    "KNN = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "LSVC = LinearSVC(max_iter=3000, tol=0.001, random_state=7)\n",
    "MNB = MultinomialNB()\n",
    "NSVC = NuSVC(nu=0.5, gamma='scale', random_state=7) # need to study about good value for nu\n",
    "SVC = SVC(gamma='scale', random_state=7)\n",
    "\n",
    "BAG = BaggingClassifier(n_estimators=100, warm_start=True, n_jobs=-1, random_state=7)\n",
    "GBC = GradientBoostingClassifier(n_estimators=100, warm_start=True, random_state=7)\n",
    "LR = LogisticRegression(solver='lbfgs', multi_class='multinomial', warm_start=True, n_jobs=-1)\n",
    "MLP1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(24, 12, 6, 3), random_state=7, warm_start=True)\n",
    "MLP2 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(12, 6, 3), random_state=7, warm_start=True)\n",
    "RFC = RandomForestClassifier(n_estimators=100, warm_start=True, n_jobs=-1, random_state=7)\n",
    "SGD = SGDClassifier(max_iter=1000, tol=0.001, n_jobs=-1, warm_start=True, random_state=7)\n",
    "XTree = ExtraTreesClassifier(n_estimators=100, warm_start=True, n_jobs=-1, random_state=7)\n",
    "\n",
    "# Vote = VotingClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'LFT_SPLICE_LENGTH',\n",
      "       'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', 'PA_S8_L',\n",
      "       'PA_S7_L', 'PA_S6_L', 'PA_S5_L', 'PA_S4_L', 'PA_S3_L', 'PA_S2_L',\n",
      "       'PA_S1_ML', 'PA_S1_MR', 'PA_S2_R', 'PA_S3_R', 'PA_S4_R', 'PA_S5_R',\n",
      "       'PA_S6_R', 'PA_S7_R', 'PA_S8_R', 'PART_LENGTH', 'LFT_SPLICE_DELTA',\n",
      "       'LFT_SPLICE_PREV', 'LFT_SPLICE_MA5', 'LFT_SPLICE_MA10',\n",
      "       'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50', 'LFT_SPLICE_SLOPE5',\n",
      "       'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50',\n",
      "       'MID_SPLICE_DELTA', 'MID_SPLICE_PREV', 'MID_SPLICE_MA5',\n",
      "       'MID_SPLICE_MA10', 'MID_SPLICE_MA20', 'MID_SPLICE_MA50',\n",
      "       'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10', 'MID_SPLICE_SLOPE20',\n",
      "       'MID_SPLICE_SLOPE50', 'RHT_SPLICE_DELTA', 'RHT_SPLICE_PREV',\n",
      "       'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10', 'RHT_SPLICE_MA20',\n",
      "       'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
      "       'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50', 'LFT_SPLICE_GRADE',\n",
      "       'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE', 'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('VMI_Data_PA_V02_AK6_mod02.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'PA_S8_L', 'PA_S7_L', 'PA_S6_L',\n",
      "       'PA_S5_L', 'PA_S4_L', 'PA_S3_L', 'PA_S2_L', 'PA_S1_ML', 'PA_S1_MR',\n",
      "       'PA_S2_R', 'PA_S3_R', 'PA_S4_R', 'PA_S5_R', 'PA_S6_R', 'PA_S7_R',\n",
      "       'PA_S8_R', 'PART_LENGTH', 'LFT_SPLICE_PREV', 'MID_SPLICE_PREV',\n",
      "       'RHT_SPLICE_PREV', 'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['LFT_SPLICE_LENGTH', 'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', \n",
    "              'LFT_SPLICE_GRADE', 'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE', 'LFT_SPLICE_DELTA', \n",
    "              'LFT_SPLICE_MA5', 'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50', \n",
    "              'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50',\n",
    "              'MID_SPLICE_DELTA', 'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
    "              'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10', 'MID_SPLICE_SLOPE20',\n",
    "              'MID_SPLICE_SLOPE50', 'RHT_SPLICE_DELTA',  'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10', \n",
    "              'RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
    "              'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50'], axis=1)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121433, 23)\n",
      "(121433, 23)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# df = df.drop_duplicates(subset=['CUT_LENGTH', 'CONV_WAIT_TIME', 'PA_S8_L', 'PA_S7_L', 'PA_S6_L', 'PA_S5_L', \n",
    "#                                 'PA_S4_L', 'PA_S3_L', 'PA_S2_L', 'PA_S1_ML', 'PA_S1_MR', 'PA_S2_R', \n",
    "#                                 'PA_S3_R', 'PA_S4_R', 'PA_S5_R', 'PA_S6_R', 'PA_S7_R', 'PA_S8_R'])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Total  Percent\n",
      "SPLICE_GRADE        0      0.0\n",
      "PA_S1_MR            0      0.0\n",
      "CONV_WAIT_TIME      0      0.0\n",
      "PA_S8_L             0      0.0\n",
      "PA_S7_L             0      0.0\n",
      "PA_S6_L             0      0.0\n",
      "PA_S5_L             0      0.0\n",
      "PA_S4_L             0      0.0\n",
      "PA_S3_L             0      0.0\n",
      "PA_S2_L             0      0.0\n"
     ]
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.head(10))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericSG(row):\n",
    "    if row['SPLICE_GRADE'] == 'Bad':\n",
    "        return 0\n",
    "    if row['SPLICE_GRADE'] == 'OK' :\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby('SPLICE_GRADE', group_keys=False).apply(lambda x: x.sample(120))\n",
    "df['SPLICE_GRADE'] = df.apply(numericSG, axis=1) \n",
    "\n",
    "# df.to_csv('temp.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier [0.36821737 0.47982543 0.79249012 0.78820817 0.78810838 0.79362596\n",
      " 0.79329655 0.75104999 0.77820787 0.76050074]\n",
      "136.90307807922363  seconds\n",
      "BernoulliNB [0.35183203 0.80854743 0.85918972 0.7928195  0.79288479 0.79288479\n",
      " 0.79288479 0.79288479 0.79295009 0.74781749]\n",
      "1.0669989585876465  seconds\n",
      "GaussianNB [0.30045286 0.60523715 0.8595191  0.79685441 0.7911554  0.79123775\n",
      " 0.77353208 0.78226139 0.79097348 0.79171471]\n",
      "1.2939977645874023  seconds\n",
      "KNeighborsClassifier [0.71288596 0.77017457 0.79323123 0.77923254 0.78662604 0.78843778\n",
      " 0.78094375 0.76702627 0.76750124 0.77351342]\n",
      "19.692012310028076  seconds\n",
      "SVC [0.79283656 0.7928195  0.7928195  0.7928195  0.79288479 0.79288479\n",
      " 0.79288479 0.79288479 0.79295009 0.79295009]\n",
      "5391.783714056015  seconds\n",
      "5391.783714056015 *** Warm startable ones ***\n",
      "BaggingClassifier [0.26628242 0.14476285 0.49431818 0.48913043 0.65090999 0.79535535\n",
      " 0.52202915 0.67635675 0.78669083 0.76107725]\n",
      "431.62950134277344  seconds\n",
      "GradientBoostingClassifier [0.30646357 0.31274704 0.70816864 0.72496706 0.79189657 0.79988471\n",
      " 0.69710945 0.78753191 0.79187943 0.79467962]\n",
      "486.8793761730194  seconds\n",
      "LogisticRegression [0.79176616 0.79265481 0.79430171 0.79331357 0.79313185 0.79304949\n",
      " 0.79313185 0.79197892 0.79303245 0.79245594]\n",
      "128.53876447677612  seconds\n",
      "MLPClassifier 1 [0.79283656 0.7928195  0.7928195  0.7928195  0.79288479 0.79288479\n",
      " 0.79288479 0.79288479 0.79295009 0.79295009]\n",
      "46.740341663360596  seconds\n",
      "RandomForestClassifier [0.24726225 0.12870553 0.45503953 0.38109354 0.59046364 0.79659063\n",
      " 0.44107716 0.60215762 0.78405535 0.78430242]\n",
      "83.03575873374939  seconds\n",
      "SGDClassifier [0.79283656 0.75205863 0.7928195  0.5479249  0.79675533 0.78860249\n",
      " 0.7913201  0.3278432  0.79295009 0.79286773]\n",
      "89.50699806213379  seconds\n",
      "ExtraTreesClassifier [0.24289831 0.12360013 0.44416996 0.33407444 0.35411348 0.67734497\n",
      " 0.39899531 0.40648934 0.62246747 0.69790809]\n",
      "65.28465461730957  seconds\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['SPLICE_GRADE'], axis=1)\n",
    "y = df['SPLICE_GRADE']\n",
    "y = y.astype('int')\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(ADA, X, y, cv=10, scoring='accuracy')\n",
    "print(\"AdaBoostClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(BNB, X, y, cv=10, scoring='accuracy')\n",
    "print(\"BernoulliNB\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(GNB, X, y, cv=10, scoring='accuracy')\n",
    "print(\"GaussianNB\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(KNN, X, y, cv=10, scoring='accuracy')\n",
    "print(\"KNeighborsClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "# time1 = time.time()\n",
    "# scores = cross_val_score(LSVC, X, y, cv=10, scoring='accuracy')\n",
    "# print(\"LinearSVC\", scores)\n",
    "# time2 = time.time()\n",
    "# print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "# time1 = time.time()\n",
    "# scores = cross_val_score(MNB, X, y, cv=10, scoring='accuracy')\n",
    "# print(\"MultinomialNB\", scores)\n",
    "# time2 = time.time()\n",
    "# print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "# time1 = time.time()\n",
    "# scores = cross_val_score(NSVC, X, y, cv=10, scoring='accuracy')\n",
    "# print(\"NuSVC\", scores)\n",
    "# time2 = time.time()\n",
    "# print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(SVC, X, y, cv=10, scoring='accuracy')\n",
    "print(\"SVC\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "\n",
    "print(\"*** Warm startable ones ***\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(BAG, X, y, cv=10, scoring='accuracy')\n",
    "print(\"BaggingClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(GBC, X, y, cv=10, scoring='accuracy')\n",
    "print(\"GradientBoostingClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(LR, X, y, cv=10, scoring='accuracy')\n",
    "print(\"LogisticRegression\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(MLP1, X, y, cv=10, scoring='accuracy')\n",
    "print(\"MLPClassifier 1\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "# time1 = time.time()\n",
    "# scores = cross_val_score(MLP2, X, y, cv=10, scoring='accuracy')\n",
    "# print(\"MLPClassifier 2\", scores)\n",
    "# time2 = time.time()\n",
    "# print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(RFC, X, y, cv=10, scoring='accuracy')\n",
    "print(\"RandomForestClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()  \n",
    "scores = cross_val_score(SGD, X, y, cv=10, scoring='accuracy')\n",
    "print(\"SGDClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n",
    "\n",
    "time1 = time.time()\n",
    "scores = cross_val_score(XTree, X, y, cv=10, scoring='accuracy')\n",
    "print(\"ExtraTreesClassifier\", scores)\n",
    "time2 = time.time()\n",
    "print(\"-- took \", time2 - time1, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Bad', 'OK', 'Good']\n",
    "class_names = target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" *********** GaussianNB *********** \")\n",
    "# y2_GNB_model = GNB.predict(x2)\n",
    "# print(classification_report(y2, y2_GNB_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "# print(\" *********** KNeighborsClassifier *********** \")\n",
    "# y2_KNN_model = KNN.predict(x2)\n",
    "# print(classification_report(y2, y2_KNN_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "# print(\" *********** LogisticRegression *********** \")\n",
    "# y2_LR_model = LR.predict(x2)\n",
    "# print(classification_report(y2, y2_LR_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "# print(\" *********** SVC *********** \")\n",
    "# y2_SVC_model = SVC.predict(x2)\n",
    "# print(classification_report(y2, y2_SVC_model, target_names=target_names, sample_weight=None, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y2, y2_GNB_model)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='GaussianNB Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='GaussianNB Normalized confusion matrix')\n",
    "\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y2, y2_KNN_model)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='KNeighborsClassifier Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='KNeighborsClassifier Normalized confusion matrix')\n",
    "\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y2, y2_SVC_model)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='SVC Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='SVC Normalized confusion matrix')\n",
    "\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out these\n",
    "# sklearn.multioutput.MultiOutputClassifier\n",
    "# sklearn.multiclass.OutputCodeClassifier\n",
    "# sklearn.multiclass.OneVsOneClassifier\n",
    "# sklearn.multiclass.OneVsRestClassifier\n",
    "# sklearn.model_selection.RandomizedSearchCV -- https://stackoverflow.com/questions/52029408/sklearn-mlp-classifier-hyperparameter-optimization-randomizedsearchcv\n",
    "# sklearn.model_selection.check_cv\n",
    "# sklearn.model_selection.StratifiedKFold\n",
    "# sklearn.linear_model.RidgeClassifierCV\n",
    "# sklearn.linear_model.PassiveAggressiveClassifier\n",
    "# sklearn.linear_model.LogisticRegressionCV\n",
    "# sklearn.gaussian_process.GaussianProcessClassifier\n",
    "# sklearn.tree.DecisionTreeClassifier\n",
    "# sklearn.tree.ExtraTreeClassifier\n",
    "# Feature significance\n",
    "# Narrow to Wide Splice\n",
    "# Prev Deltas MA & Slope\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
