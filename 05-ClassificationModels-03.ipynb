{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries required for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our classifiers\n",
    "BNB = BernoulliNB()\n",
    "GNB = GaussianNB()\n",
    "KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "LR = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "LSVC = LinearSVC(max_iter=2000, tol=0.001)\n",
    "MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, warm_start=True)\n",
    "MNB = MultinomialNB()\n",
    "# NSVC = NuSVC(gamma='scale') # need to study about good value for nu\n",
    "SGD = SGDClassifier(max_iter=1000, tol=0.001)\n",
    "SVC = SVC(gamma='scale')\n",
    "\n",
    "\n",
    "ADA = AdaBoostClassifier()\n",
    "BAG = BaggingClassifier()\n",
    "XTree = ExtraTreesClassifier()\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "# Vote = VotingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'LFT_SPLICE_LENGTH',\n",
      "       'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', 'BP1_S8_L',\n",
      "       'BP1_S7_L', 'BP1_S6_L', 'BP1_S5_L', 'BP1_S4_L', 'BP1_S3_L', 'BP1_S2_L',\n",
      "       'BP1_S1_ML', 'BP1_S1_MR', 'BP1_S2_R', 'BP1_S3_R', 'BP1_S4_R',\n",
      "       'BP1_S5_R', 'BP1_S6_R', 'BP1_S7_R', 'BP1_S8_R', 'BP1_LENGTH',\n",
      "       'LFT_SPLICE_DELTA', 'LFT_SPLICE_PREV', 'LFT_SPLICE_MA5',\n",
      "       'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50',\n",
      "       'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20',\n",
      "       'LFT_SPLICE_SLOPE50', 'MID_SPLICE_DELTA', 'MID_SPLICE_PREV',\n",
      "       'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
      "       'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10',\n",
      "       'MID_SPLICE_SLOPE20', 'MID_SPLICE_SLOPE50', 'RHT_SPLICE_DELTA',\n",
      "       'RHT_SPLICE_PREV', 'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10',\n",
      "       'RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5',\n",
      "       'RHT_SPLICE_SLOPE10', 'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50',\n",
      "       'LFT_SPLICE_GRADE', 'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE',\n",
      "       'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('VMI_Data_BP1_V02_AK6_mod02.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CUT_LENGTH', 'CONV_WAIT_TIME', 'BP1_S8_L', 'BP1_S7_L', 'BP1_S6_L',\n",
      "       'BP1_S5_L', 'BP1_S4_L', 'BP1_S3_L', 'BP1_S2_L', 'BP1_S1_ML',\n",
      "       'BP1_S1_MR', 'BP1_S2_R', 'BP1_S3_R', 'BP1_S4_R', 'BP1_S5_R', 'BP1_S6_R',\n",
      "       'BP1_S7_R', 'BP1_S8_R', 'BP1_LENGTH', 'LFT_SPLICE_PREV',\n",
      "       'MID_SPLICE_PREV', 'RHT_SPLICE_PREV', 'SPLICE_GRADE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['LFT_SPLICE_LENGTH', 'MID_SPLICE_LENGTH', 'RHT_SPLICE_LENGTH', 'SPLICE_OK', \n",
    "              'LFT_SPLICE_GRADE', 'MID_SPLICE_GRADE', 'RHT_SPLICE_GRADE', 'LFT_SPLICE_DELTA', \n",
    "              'LFT_SPLICE_MA5', 'LFT_SPLICE_MA10', 'LFT_SPLICE_MA20', 'LFT_SPLICE_MA50', \n",
    "              'LFT_SPLICE_SLOPE5', 'LFT_SPLICE_SLOPE10', 'LFT_SPLICE_SLOPE20', 'LFT_SPLICE_SLOPE50',\n",
    "              'MID_SPLICE_DELTA', 'MID_SPLICE_MA5', 'MID_SPLICE_MA10', 'MID_SPLICE_MA20',\n",
    "              'MID_SPLICE_MA50', 'MID_SPLICE_SLOPE5', 'MID_SPLICE_SLOPE10', 'MID_SPLICE_SLOPE20',\n",
    "              'MID_SPLICE_SLOPE50', 'RHT_SPLICE_DELTA',  'RHT_SPLICE_MA5', 'RHT_SPLICE_MA10', \n",
    "              'RHT_SPLICE_MA20', 'RHT_SPLICE_MA50', 'RHT_SPLICE_SLOPE5', 'RHT_SPLICE_SLOPE10',\n",
    "              'RHT_SPLICE_SLOPE20', 'RHT_SPLICE_SLOPE50'], axis=1)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Total  Percent\n",
      "SPLICE_GRADE        0      0.0\n",
      "BP1_S1_MR           0      0.0\n",
      "CONV_WAIT_TIME      0      0.0\n",
      "BP1_S8_L            0      0.0\n",
      "BP1_S7_L            0      0.0\n",
      "BP1_S6_L            0      0.0\n",
      "BP1_S5_L            0      0.0\n",
      "BP1_S4_L            0      0.0\n",
      "BP1_S3_L            0      0.0\n",
      "BP1_S2_L            0      0.0\n"
     ]
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.head(10))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['SPLICE_GRADE']==\"Good\")]=2\n",
    "df[(df['SPLICE_GRADE']==\"OK\")]=1\n",
    "df[(df['SPLICE_GRADE']==\"Bad\")]=0\n",
    "# df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ********** FOLD -  1  ********** \n",
      "BernoulliNB Accuracy : 0.9774486989634017\n",
      "GaussianNB Accuracy : 1.0\n",
      "KNeighborsClassifier Accuracy : 1.0\n",
      "LogisticRegression Accuracy : 1.0\n",
      "LinearSVC Accuracy : 0.9774486989634017\n",
      "MLPClassifier Accuracy : 0.9774486989634017\n",
      "MultinomialNB Accuracy : 0.7909879416120161\n",
      "SGDClassifier Accuracy : 0.9774486989634017\n",
      "SVC Accuracy : 1.0\n",
      "AdaBoostClassifier Accuracy : 1.0\n",
      "BaggingClassifier Accuracy : 1.0\n",
      "ExtraTreesClassifier Accuracy : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SajidPatel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier Accuracy : 1.0\n",
      "RandomForestClassifier Accuracy : 1.0\n",
      " ********** FOLD -  2  ********** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SajidPatel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy : 0.9781256610958324\n",
      "GaussianNB Accuracy : 1.0\n",
      "KNeighborsClassifier Accuracy : 1.0\n",
      "LogisticRegression Accuracy : 1.0\n",
      "LinearSVC Accuracy : 0.9781256610958324\n",
      "MLPClassifier Accuracy : 0.9781256610958324\n",
      "MultinomialNB Accuracy : 0.7946689232071081\n",
      "SGDClassifier Accuracy : 0.9781256610958324\n",
      "SVC Accuracy : 1.0\n",
      "AdaBoostClassifier Accuracy : 1.0\n",
      "BaggingClassifier Accuracy : 1.0\n",
      "ExtraTreesClassifier Accuracy : 1.0\n",
      "GradientBoostingClassifier Accuracy : 1.0\n",
      "RandomForestClassifier Accuracy : 1.0\n",
      " ********** FOLD -  3  ********** \n",
      "BernoulliNB Accuracy : 0.9782516713209782\n",
      "GaussianNB Accuracy : 1.0\n",
      "KNeighborsClassifier Accuracy : 1.0\n",
      "LogisticRegression Accuracy : 1.0\n",
      "LinearSVC Accuracy : 0.9782516713209782\n",
      "MLPClassifier Accuracy : 0.9782516713209782\n",
      "MultinomialNB Accuracy : 0.7973681983582974\n",
      "SGDClassifier Accuracy : 0.9782516713209782\n",
      "SVC Accuracy : 1.0\n",
      "AdaBoostClassifier Accuracy : 1.0\n",
      "BaggingClassifier Accuracy : 1.0\n",
      "ExtraTreesClassifier Accuracy : 1.0\n",
      "GradientBoostingClassifier Accuracy : 1.0\n",
      "RandomForestClassifier Accuracy : 1.0\n",
      " ********** FOLD -  4  ********** \n",
      "BernoulliNB Accuracy : 0.9765591943809766\n",
      "GaussianNB Accuracy : 1.0\n",
      "KNeighborsClassifier Accuracy : 1.0\n",
      "LogisticRegression Accuracy : 1.0\n",
      "LinearSVC Accuracy : 0.9765591943809766\n",
      "MLPClassifier Accuracy : 0.9765591943809766\n",
      "MultinomialNB Accuracy : 0.7907252263687907\n",
      "SGDClassifier Accuracy : 0.9765591943809766\n",
      "SVC Accuracy : 1.0\n",
      "AdaBoostClassifier Accuracy : 1.0\n",
      "BaggingClassifier Accuracy : 1.0\n",
      "ExtraTreesClassifier Accuracy : 1.0\n",
      "GradientBoostingClassifier Accuracy : 1.0\n",
      "RandomForestClassifier Accuracy : 1.0\n",
      " ********** FOLD -  5  ********** \n",
      "BernoulliNB Accuracy : 0.9768553778454768\n",
      "GaussianNB Accuracy : 1.0\n",
      "KNeighborsClassifier Accuracy : 1.0\n",
      "LogisticRegression Accuracy : 1.0\n",
      "LinearSVC Accuracy : 0.9768553778454768\n",
      "MLPClassifier Accuracy : 0.9768553778454768\n",
      "MultinomialNB Accuracy : 0.7981721249047982\n",
      "SGDClassifier Accuracy : 0.9768553778454768\n",
      "SVC Accuracy : 1.0\n",
      "AdaBoostClassifier Accuracy : 1.0\n",
      "BaggingClassifier Accuracy : 1.0\n",
      "ExtraTreesClassifier Accuracy : 1.0\n",
      "GradientBoostingClassifier Accuracy : 1.0\n",
      "RandomForestClassifier Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['SPLICE_GRADE'], axis=1)\n",
    "y = df['SPLICE_GRADE']\n",
    "y = y.astype('int')\n",
    "\n",
    "fold = 1\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x1, x2 = X.iloc[train_index], X.iloc[test_index]\n",
    "    y1, y2 = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\" ********** FOLD - \", fold, \" ********** \")\n",
    "    # Train our classifier and test predict\n",
    "    BNB.fit(x1,y1)\n",
    "    y2_BNB_model = BNB.predict(x2)\n",
    "    print(\"BernoulliNB Accuracy :\", accuracy_score(y2, y2_BNB_model))\n",
    "\n",
    "    GNB.fit(x1, y1)\n",
    "    y2_GNB_model = GNB.predict(x2)\n",
    "    print(\"GaussianNB Accuracy :\", accuracy_score(y2, y2_GNB_model))\n",
    "\n",
    "    KNN.fit(x1,y1)\n",
    "    y2_KNN_model = KNN.predict(x2)\n",
    "    print(\"KNeighborsClassifier Accuracy :\", accuracy_score(y2, y2_KNN_model))\n",
    "\n",
    "    LR.fit(x1,y1)\n",
    "    y2_LR_model = LR.predict(x2)\n",
    "    print(\"LogisticRegression Accuracy :\", accuracy_score(y2, y2_LR_model))\n",
    "\n",
    "    LSVC.fit(x1,y1)\n",
    "    y2_LSVC_model = LSVC.predict(x2)\n",
    "    print(\"LinearSVC Accuracy :\", accuracy_score(y2, y2_LSVC_model))\n",
    "\n",
    "    MLP.fit(x1,y1)\n",
    "    y2_MLP_model = MLP.predict(x2)\n",
    "    print(\"MLPClassifier Accuracy :\", accuracy_score(y2, y2_MLP_model))\n",
    "    \n",
    "    MNB.fit(x1,y1)\n",
    "    y2_MNB_model = MNB.predict(x2)\n",
    "    print(\"MultinomialNB Accuracy :\", accuracy_score(y2, y2_MNB_model))\n",
    "    \n",
    "#     NSVC.fit(x1,y1)\n",
    "#     y2_NSVC_model = NSVC.predict(x2)\n",
    "#     print(\"NuSVC Accuracy :\", accuracy_score(y2, y2_NSVC_model))\n",
    "    \n",
    "    SGD.fit(x1,y1)\n",
    "    y2_SGD_model = SGD.predict(x2)\n",
    "    print(\"SGDClassifier Accuracy :\", accuracy_score(y2, y2_SGD_model))\n",
    "    \n",
    "    SVC.fit(x1,y1)\n",
    "    y2_SVC_model = SVC.predict(x2)\n",
    "    print(\"SVC Accuracy :\", accuracy_score(y2, y2_SVC_model))\n",
    "    \n",
    "    ADA.fit(x1,y1)\n",
    "    y2_ADA_model = ADA.predict(x2)\n",
    "    print(\"AdaBoostClassifier Accuracy :\", accuracy_score(y2, y2_ADA_model))\n",
    "    \n",
    "    BAG.fit(x1,y1)\n",
    "    y2_BAG_model = BAG.predict(x2)\n",
    "    print(\"BaggingClassifier Accuracy :\", accuracy_score(y2, y2_BAG_model))\n",
    "\n",
    "    XTree.fit(x1,y1)\n",
    "    y2_XTree_model = XTree.predict(x2)\n",
    "    print(\"ExtraTreesClassifier Accuracy :\", accuracy_score(y2, y2_XTree_model))\n",
    "\n",
    "    GBC.fit(x1,y1)\n",
    "    y2_GBC_model = GBC.predict(x2)\n",
    "    print(\"GradientBoostingClassifier Accuracy :\", accuracy_score(y2, y2_GBC_model))\n",
    "\n",
    "    RFC.fit(x1,y1)\n",
    "    y2_RFC_model = RFC.predict(x2)\n",
    "    print(\"RandomForestClassifier Accuracy :\", accuracy_score(y2, y2_RFC_model))\n",
    "    \n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Bad', 'OK', 'Good']\n",
    "class_names = target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *********** GaussianNB *********** \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b9c8d19a51c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" *********** GaussianNB *********** \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_GNB_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" *********** KNeighborsClassifier *********** \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_KNN_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_names' is not defined"
     ]
    }
   ],
   "source": [
    "print(\" *********** GaussianNB *********** \")\n",
    "print(classification_report(y2, y2_GNB_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "print(\" *********** KNeighborsClassifier *********** \")\n",
    "print(classification_report(y2, y2_KNN_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "print(\" *********** LogisticRegression *********** \")\n",
    "print(classification_report(y2, y2_LR_model, target_names=target_names, sample_weight=None, digits=4))\n",
    "\n",
    "print(\" *********** SVC *********** \")\n",
    "print(classification_report(y2, y2_SVC_model, target_names=target_names, sample_weight=None, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y2, y2_GNB_model)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='GaussianNB Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='GaussianNB Normalized confusion matrix')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y2, y2_KNN_model)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='KNeighborsClassifier Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='KNeighborsClassifier Normalized confusion matrix')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y2, y2_SVC_model)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='SVC Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='SVC Normalized confusion matrix')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out these\n",
    "# sklearn.multioutput.MultiOutputClassifier\n",
    "# sklearn.multiclass.OutputCodeClassifier\n",
    "# sklearn.multiclass.OneVsOneClassifier\n",
    "# sklearn.multiclass.OneVsRestClassifier\n",
    "# sklearn.model_selection.RandomizedSearchCV -- https://stackoverflow.com/questions/52029408/sklearn-mlp-classifier-hyperparameter-optimization-randomizedsearchcv\n",
    "# sklearn.model_selection.check_cv\n",
    "# sklearn.model_selection.StratifiedKFold\n",
    "# sklearn.linear_model.RidgeClassifierCV\n",
    "# sklearn.linear_model.PassiveAggressiveClassifier\n",
    "# sklearn.linear_model.LogisticRegressionCV\n",
    "# sklearn.gaussian_process.GaussianProcessClassifier\n",
    "# sklearn.tree.DecisionTreeClassifier\n",
    "# sklearn.tree.ExtraTreeClassifier\n",
    "# Feature significance\n",
    "# Narrow to Wide Splice\n",
    "# Prev Deltas MA & Slope\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
